# Object Tracking 目标跟踪

在 [Research - Object Detection](./object_detection.md) 中，我们限定 YOLO 只从图像中识别一个 person 类的目标进行定位，限制条件太多，显然无法应对实际的多目标场景，这也体现了单纯目标检测的局限性。目标检测通常只能检测出图片或者视频流中的目标具体属于哪一类别，并不能直接长时间的追踪这个目标，此时就需要使用**目标跟踪**算法来实现这一目的。

例如 YOLO 只能从图中检测出目标类别、边界框、置信度等帧间独立的信息，但是无法得知目标的特征信息，也就无法从连续的图像中得知是否为某一具体的目标。也就是说，从结果上来看，YOLO 能持续识别到多个目标，但是它本身不知道这是同一个目标、同一个物体。

??? note "Track Mode in Ultralytics YOLO"
    在早期的 YOLOv3–YOLOv5，YOLO 只负责目标检测（Detection），也就是输出边界框。从 YOLOv8 开始，官方 CLI 和 API 内置了多目标跟踪模块，也就是 Task 中的 Track Mode，参考 [Multi-Object Tracking with Ultralytics YOLO](https://docs.ultralytics.com/modes/track/)。但是 YOLO 自身仍然只负责检测部分，而 “Track” 功能其实是集成了外部 MOT 算法，如 ByteTrack、BoT-SORT、StrongSORT 等，整体上是 Tracking-by-Detection 架构。YOLO 负责输出检测框，Tracker 负责将同一目标在不同帧关联起来。

    ```bash
    yolo track model=yolov8s.pt source=video.mp4 tracker=bytetrack.yaml
    ```

    可一次完成“检测 + 跟踪 + ID 分配 + 输出轨迹”的任务。

    目前 YOLO Track 的局限性在于，使用的 Tracking-by-Detection 架构中检测与跟踪分离，非联合优化，无法端到端学习。

目标跟踪（Object Tracking）是自动驾驶中的常见任务，根据跟踪目标数量的不同，目标跟踪可分为：

- 单目标跟踪（Single Object Tracking，SOT）
- 多目标跟踪（Multi-Objects Tracking，MOT）

## MOT Basic

由于单目标跟踪相对较为简单，且可以看作是多目标跟踪的特殊情况，因此这里主要讨论的都是**多目标跟踪**算法。多目标跟踪算以分为两类，分别是基于检测的跟踪（TBD，Tracking-by-Detection）和联合检测跟踪（JDT，Joint Detection & Tracking）。基于检测的跟踪结构简单，跟踪效果与检测效果联系紧密，而联合检测跟踪类算法通常融合了多模块联合学习，在多项跟踪评价指标中表现出色。[^1]

典型的多目标跟踪系统框架如下所示：

![20251029122825](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251029122825.png)

目标跟踪所要做的是根据传感器测量序列确定真实目标的数量以及每个目标的对应状态（位置、速度、航向等），具体实现可大体分为三部分：

- 状态估计
- 数据关联
- 航迹管理

其中，数据关联（Data Association）是目标跟踪中最具挑战的任务之一。对于单目标跟踪而言，数据关联要解决的是传感器测量能否与跟踪目标关联上；对于多目标跟踪而言，数据关联要解决的是哪个传感器测量能与哪个跟踪目标关联上，即跟踪目标与传感器测量的一一对应关系。目前，数据关联已发展出多种理论与算法，包括但不限于：

- 最近邻（Nearest Neighbor，NN）
- 概率数据关联（Probability Data Association，PDA）
- 联合概率数据关联（Joint Probability Data Association，JPDA）
- 多假设跟踪（Multiple Hypothesis Tracking，MHT）
- 随机有限集（Random Finite Set，RFS）
- 匈牙利算法（Hungarian Algorithm）

> The following contents are generated by ChatGPT.

多目标跟踪的三大路线：

| 路线                                     | 核心思想                                          | 代表算法                                     |
| ---------------------------------------- | ------------------------------------------------- | -------------------------------------------- |
| 1️⃣ Tracking-by-Detection                  | 先检测再关联（最主流）                            | SORT、DeepSORT、ByteTrack、OC-SORT、BoT-SORT |
| 2️⃣ Joint Detection & Tracking（端到端）   | 检测与跟踪联合训练                                | JDE、FairMOT、CenterTrack、TransTrack        |
| 3️⃣ Tracking-by-Embedding（ReID 特征匹配） | 把目标 ID 嵌入特征空间，通过 embedding 相似性跟踪 | DeepSORT、BoT-SORT、StrongSORT、DeepMOT      |

按照类型可以归纳为：

| 类别           | 算法              | 使用 ReID | 速度 | 鲁棒性 | 优势场景         |
| -------------- | ----------------- | --------- | ---- | ------ | ---------------- |
| 传统几何型     | SORT              | ❌         | ⭐⭐⭐⭐ | ⭐      | 静态、无遮挡场景 |
|                | OC-SORT           | ❌         | ⭐⭐⭐⭐ | ⭐⭐⭐    | 稍复杂场景       |
| 外观增强型     | DeepSORT          | ✅         | ⭐⭐⭐  | ⭐⭐⭐⭐   | 遮挡、行人       |
|                | BoT-SORT          | ✅         | ⭐⭐   | ⭐⭐⭐⭐⭐  | 相机运动场景     |
|                | StrongSORT        | ✅         | ⭐⭐   | ⭐⭐⭐⭐⭐  | 大遮挡场景       |
| 检测联合型     | JDE               | ✅         | ⭐⭐⭐  | ⭐⭐⭐    | 实时端到端       |
|                | FairMOT           | ✅         | ⭐⭐⭐  | ⭐⭐⭐⭐   | 行人跟踪标准     |
|                | ByteTrack         | ❌         | ⭐⭐⭐⭐ | ⭐⭐⭐⭐   | 各类目标、通用   |
| Transformer 型 | CenterTrack       | ❌         | ⭐⭐⭐  | ⭐⭐⭐    | 中等复杂场景     |
|                | TransTrack / MOTR | ✅         | ⭐    | ⭐⭐⭐⭐   | 高精度、研究级   |

常用评价指标：

| 符号                    | 全称    | 含义                                      | 举例                                     |
| ----------------------- | ------- | ----------------------------------------- | ---------------------------------------- |
| **TP (True Positive)**  | 真阳性  | 检测框与真值框匹配成功（IoU > 阈值）      | 检测到一个人，而且框得很准               |
| **FP (False Positive)** | 假阳性  | 检测出了不存在的目标                      | 没有人却输出了框，或同一人重复输出多个框 |
| **FN (False Negative)** | 假阴性  | 真值中有目标却没检测出来                  | 有人但被漏检                             |
| **IDSW (ID Switch)**    | ID 切换 | 同一个人被赋予不同 ID、或不同人被错误合并 | 跟踪过程中 ID 更换、或两人 ID 互换       |

| 指标          | 全称                            | 衡量对象      | 优点           | 缺点           |
| ------------- | ------------------------------- | ------------- | -------------- | -------------- |
| **MOTA**      | Multi-Object Tracking Accuracy  | 综合精度      | 简单直观       | 对 ID 敏感性弱 |
| **MOTP**      | Multi-Object Tracking Precision | 定位误差      | 定位精度好解释 | 无法反映 ID    |
| **IDF1**      | ID-based F1 Score               | ID 一致性     | 衡量身份连贯性 | 对检测弱敏感   |
| **HOTA**      | Higher Order Tracking Accuracy  | 检测+关联平衡 | 反映全面       | 计算复杂       |
| **MT/ML**     | Mostly Tracked / Lost           | 轨迹覆盖率    | 直观易懂       | 粗略           |
| **Frag/IDSW** | Fragment / ID Switch            | 轨迹连续性    | 补充指标       | 粗粒度         |

常用公开数据集：

| 数据集                   | 场景           | 特点                       | 标注类别            |
| ------------------------ | -------------- | -------------------------- | ------------------- |
| **MOT15 / 16 / 17 / 20** | 行人跟踪       | 最经典的 MOTChallenge 系列 | person              |
| **DanceTrack (2022)**    | 群舞场景       | 同外观高遮挡               | person              |
| **KITTI MOT**            | 车载           | 自动驾驶视角               | car, pedestrian     |
| **BDD100K MOT**          | 大规模城市道路 | 多类别、多天气             | car, person, rider… |
| **TAO / TAO-MOT**        | 通用场景跟踪   | 类别多，尺度变化大         | 多类目标            |
| **VisDrone / UAVDT**     | 航拍           | 目标小、运动剧烈           | person, car         |
| **CrowdHuman**           | 行人密集       | 行人检测与 ReID 联合       | person              |

---

在介绍具体的工程算法之前，我们先介绍常用的数学理论算法——匈牙利算法。

## Kuhn Algorithm (unweighted Hungarian)

> 以下部分内容参考[匈牙利算法-看这篇绝对就够了！-CSDN博客](https://blog.csdn.net/u013384984/article/details/90718287)。

匈牙利算法（Hungarian Algorithm）一种求解最优匹配问题的经典算法，用于在代价矩阵中找到任务与工人之间的最优一对一分配，使总代价最小（或收益最大）。其核心思想是通过矩阵行列变换和零元素匹配，逐步寻找完美匹配并调整未匹配元素的权值，从而得到最优解。

匈牙利算法一般使用的是**带权无向图**，我们可以先从特殊情况——无权无向图开始讨论，此时退化为 Kuhn Algorithm。接下来，我们需要回顾一些离散数学中的知识（以下内容摘自艾颖华老师《离散数学讲义》）：

### Definition

- 称 $G$ 是**二部分图**（二部图），如果可以将 $V(G)$ 表示为两个子集的不交并 $G=A\cup B$ ，使得 $A$ 中的顶点彼此不相邻、 $B$ 中的顶点彼此不相邻，记为二部图 $G=(A,B,E)$ .
- 二部图 $G=(A,B,E)$ 的一个**匹配**，是指边集 $E$ 的一个子集 $M$ ，要求 $M$ 的成员没有公共顶点。
- 称匹配 $M$ 是从 $A$ 到 $B$ 的一个**完全匹配**，如果对 $A$ 中每一个顶点 $a\in A$ ，满足 $M$ 中都有以 $a$ 为顶点的边。进一步地，称 $M$ 为**完美匹配**（perfect matching），如果每个顶点都是 $M$ 中某个边的端点。
- 设 $M$ 是二部图 $G = (A \cup B, E)$ 的一个匹配，称 $G$ 的顶点 $v$ 是**自由顶点**，如果 $M$ 中没有以 $v$ 为顶点的边。
- 称简单路 $P$ 是相对于匹配 $M$ 的**增广路**（augmenting path），如果 $P$ 的起点 $u$ 是 $A$ 的自由顶点，终点是 $B$ 的自由顶点，且 $P$ 的第偶数条边都属于 $M$，其余边属于 $E - M$。换句话说，简单路 $P$ 是增广路，如果它的端点都是自由顶点，且属于 $M$ 的边与不属于 $M$ 的边在 $P$ 上交替出现。

上面的数学语言略显抽象，我们使用更加通俗易懂的语言重新描述一遍：

- 二部图 $G=(A\cup B, E)$ ：顶点划分为左右两部分 $A,B$ ，只存在连接 $A,B$ 之间的边，不存在 $A,B$ 内部的边。
- 匹配 $M$ ：边集的一个子集，任意两条边无公共端点，相当于给工人一一分配任务。
- 完全匹配/最大匹配：边数最多的匹配，再加任何一条就会冲突，且不一定覆盖所有顶点。
- 完美匹配：图中每个点都被匹配到。这要求图的顶点数一定为偶数。
- 自由顶点：匹配 $M$ 中没有边连接的顶点。
- 简单路：没有重复顶点的道路。
- 增广路：起点和终点都是自由顶点，沿着路径走，属于 $M$ 的边和不属于 $E-M$ 的边交替出现。由于首尾边都不属于 $M$ ，因此整条路的边数一定为奇数。

另外，完美匹配就像是一个定义到 $A$ 和 $B$ 之间的双射，两个集合中的元素一一对应，就像是 $n$ 个男人和 $n$ 个女人，他们之间可能互有好感（一个男人可能对多个女人有好感，一个女人可能对多个男人有好感，及每个顶点都可能有多条连接其他顶点的边），完美匹配就是找到一种配偶方式，使得每一对配偶都是互有好感的。但实际中，我们通常很难做到完美匹配，但是可以做到完全匹配。完全匹配相当于，撮合任何一对互有好感的男女，最多能成全多少对情侣。那么如何找到完全匹配？关键就是找到增广路径。

### Algorithm

> Berge's lemma: $M$ 是 $G$ 的完全匹配的充要条件是，不存在相对于 $M$ 的增广路径。
>
> Hall's marriage theorem: 二部分图 $G=(A\cup B,E)$ 存在 $A\to B$ 完全匹配的充要条件是， $\forall S\subseteq A$ 都有 $|N(S)|\geqslant |S|$ 。其中 $N(S)$ 是 $S$ 集中所有点的邻点的集合。

![20251027214022](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251027214022.png)

例如上面的图，边集“2，4”是一个匹配，但同时边集“1，3，5”也是一个匹配，而且边数更多。如果我们从边“2，4”出发，会发现“1，2，3，4，5”是一个增广路径，而去除“2，4”之后就得到了一个更大的匹配。因此自然地，寻找完全匹配就是在已有匹配的情况下，不断寻找增广路径，因为出现一条增广路径，就意味着匹配中可以增加一条边。

我们来看一个例子：

![20251027215023](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251027215023.png)

对于这样一个二部图，我们从左向右寻找完全匹配，我们的目标是尽可能给 $X$ 中最多的点找到到配对。注意，完全匹配是互相的，如果我们给 $X$ 找到了最多的 $Y$ 中的对应点，同样， $Y$ 中也不可能有更多的点得到匹配。

初始时，我们选择 $(x_1,y_1)$ 边构建匹配，已配对的边加粗。

![20251027215527](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251027215527.png)

接下来给 $x_2$ 添加匹配 $(x_2,y_2)$ ：

![20251027215611](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251027215611.png)

接下来，给 $x_3$ 添加匹配的时候，发现它的第一条边的另一端 $y_1$ 已经被 $x_1$ 占用，于是抢走了 $y_1$ ，而 $x_1$ 重新寻找匹配，发现第二条边的另一端 $y_2$ 已经被 $x_2$ 占用，于是抢走了 $y_2$ ，而 $x_2$ 重新寻找匹配，直接匹配到 $y_5$ 。这样的“发现冲突-抢占-重新寻找匹配”的操作也是一个递归的过程。

![20251027220304](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251027220304.png)

在上述过程中涉及到的顶点，依次为 $P=(x_3,y_1,x_1,y_2,x_2,y_5)$ ，我们发现组成的这条路径竟然是匹配 $M=(x_1-y_1,x_2-y_2)$ 的一个增广路径！Amazing！我们将 $M$ 中的配对点拆分开，重新组合，得到了一个更大匹配 $M'=(x_1-y_2,x_2-y_5,x_3-y_3)$ 。

此时还有一个问题，那就是上述操作中，各个顶点依次挤掉其他的顶点，最后一个顶点发现还是有归宿的。但是如果最后发现最后一个点没有其他可用的匹配了呢？例如 $x_2$ 没有连接 $y_5$ ，那就意味着增广路径寻找失败，新到来的点 $x_3$ 无法加入到当前匹配，将会寻找下一个顶点 $x_4$ 的匹配。

最后把 $x_4,x_5$ 配对，得到这个图的一个完全匹配：

![20251027220539](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251027220539.png)

最后总结一下，匈牙利算法的核心，就是不断寻找原有匹配 $M$ 的增广路径，由此，这条增广路径减去 $M$ 就得到一个更大的匹配 $M'$ ，恰好比 $M$ 多一条边。对于一般的图来说，完全匹配可能不唯一，但是完全匹配的大小是唯一的。

### Code

接下来给出一个匈牙利算法的简单 Python 实现，二部图使用邻接链表（adjacency list）表示，以及一个 C++ 实现，二部图使用邻接矩阵表示（adjacency matrix）：

=== "Python"

    ```py
    def hungarian(adj: list[list[int]]) -> dict[int, int]:
        """匈牙利算法 (DFS 版本)，求解二部图最大匹配

        本函数使用深度优先搜索 (DFS) 实现无权二部图的最大匹配算法。
        输入为左侧顶点的邻接表，输出右侧顶点的匹配结果。

        Args:
            adj (List[List[int]]):
                二部图的邻接表。
                其中 adj[u] 表示左侧顶点 u 能连接的所有右侧顶点编号列表。
                顶点编号通常从 0 开始计数。

        Returns:
            dict[int, int]:
                一个字典，表示匹配结果。
                键为右侧顶点编号 (v)，值为与之匹配的左侧顶点编号 (u)。
                例如 {1: 0, 2: 3} 表示右顶点1匹配左顶点0，右顶点2匹配左顶点3。

        Example:
            >>> adj = [
            ...     [1, 2],   # 左侧顶点0
            ...     [1, 3],   # 左侧顶点1
            ...     [2, 3],   # 左侧顶点2
            ...     [2, 4]    # 左侧顶点3
            ... ]
            >>> hungarian(adj)
            {1: 0, 2: 2, 3: 1, 4: 3}
        """

        matched = {}

        def match(u: int, visited: set) -> bool:
            for v in adj[u]:
                if v in visited:
                    continue
                visited.add(v)
                if v not in matched or match(matched[v], visited):
                    # 如果 v 还没有匹配，或者能为 v 当前的匹配重新找一个位置
                    matched[v] = u
                    return True
            return False

        for u in range(len(adj)):
            # 必须在外部初始化空集合，因为递归过程需要共享 visited
            visited = set()
            match(u, visited)

        return matched


    if __name__ == "__main__":
        adj = [
            [1, 2],  # 左侧顶点0
            [1, 3],  # 左侧顶点1
            [2, 3],  # 左侧顶点2
            [2, 4],  # 左侧顶点3
        ]
        result = hungarian(adj)
        print(result)
    ```

=== "C++"

    ```cpp
    #include <iostream>
    #include <vector>

    // 尝试为左侧顶点 u 寻找匹配
    bool match(int u,
            const std::vector<std::vector<int>> &adj,
            std::vector<int> &matched,
            std::vector<bool> &visited)
    {
        int n_right = adj[0].size();
        for (int v = 0; v < n_right; v++)
        {
            if (adj[u][v] && !visited[v])
            {
                visited[v] = true;
                if (matched[v] == -1 || match(matched[v], adj, matched, visited))
                {
                    matched[v] = u;
                    return true;
                }
            }
        }
        return false;
    }

    // 匈牙利算法函数
    std::vector<int> hungarian(const std::vector<std::vector<int>> &adj)
    {
        int n_left = adj.size();
        int n_right = adj[0].size();
        std::vector<int> matched(n_right, -1); // matched[v] = 与右顶点 v 匹配的左顶点编号

        for (int u = 0; u < n_left; u++)
        {
            std::vector<bool> visited(n_right, false);
            match(u, adj, matched, visited);
        }

        return matched;
    }

    int main()
    {
        // 邻接矩阵（1 表示连边，0 表示无边）
        std::vector<std::vector<int>> adj = {
            {1, 1, 0, 0}, // 左0连接右1,2
            {1, 0, 1, 0}, // 左1连接右1,3
            {0, 1, 1, 0}, // 左2连接右2,3
            {0, 1, 0, 1}  // 左3连接右2,4
        };

        // 调用算法
        std::vector<int> res = hungarian(adj);

        // 输出结果
        std::cout << "匹配结果 (右 -> 左):\n";
        for (int v = 0; v < (int)res.size(); ++v)
        {
            if (res[v] != -1)
                std::cout << "右 " << v + 1 << " ← 左 " << res[v] << '\n';
        }

        return 0;
    }
    ```

## Kuhn-Munkres Algorithm (weighted Hungarian)

> 以下部分内容参考自：
>
> [Kuhn-Munkres 算法 - Safe House](https://piggerzzm.github.io/2020/03/28/Kuhn-Munkres/)
>
> [Kuhn-Munkres 算法详细解析 - Sengxian's Blog](https://blog.sengxian.com/algorithms/km)

上述讨论的简单情形的 Kuhn Algorithm 只能判断能否匹配，求解最大匹配，不关心代价，也无法求“最小代价匹配”。而真正需要最小化匹配代价的，是带有权重的匈牙利算法 Kuhn-Munkres Algorithm。它使用的是有权无向图，等价于一个代价矩阵。例如工人任务分配问题中，工人集合和任务集合组成一个二部分图，某个工人完成某项任务的代价即为连接该工人和该任务的边的权值。

KM 算法的目标是在带权二部图中寻找最佳一一匹配，也就是：

$$
\min_\pi \sum_{i=1}^n c_{i,\pi(i)}
$$

其中：

- $c_{i,j}$ ：左顶点 $i$ 到右顶点 $j$ 的代价；
- $\pi(i)$ ：表示 $i$ 被分配到的右顶点；
- $n$ ：左、右两侧顶点数量相等（若不等可补零）。

这就是**最小代价匹配**（minimum-cost perfect matching），也叫**任务分配问题（Assignment Problem）**。

但如果要最大化权重问题，只需做简单变换：

$$
\max_{\pi} \sum_{i=1}^n w_{i,\pi(i)} \iff
\min_{\pi} \sum_{i=1}^n (-w_{i,\pi(i)})
$$

只要把代价矩阵 `cost = -weight`，再调用最小化版本的 KM 即可。

因为很多 KM 实现（包括 `scipy`）不支持负权，因此通常加一个偏移量保证代价为正：

$$
c'_{i,j} = \max_w\{w_{i,j}\}
$$

这样一来，越大的权重对应越小的代价，KM 算法仍然能正确求出最大权匹配，且不会产生负数问题。

### Definition

- 顶标：是一个节点函数 $l:V\to\mathbb{R}$ ，就是给每个顶点一个标号，可以简单理解为节点的值。
- 可行顶标：对所有顶标都满足 $l(x)+l(y)\geqslant w(x,y),\forall x\in X,y\in Y$ ，也就是边的权值不能超过两个端点的顶标之和。KM 算法的顶标必须满足这一条件。
- 相等子图：图 $G=(V,E)$ 的相等子图 $G_l=(V,E_l)$ ，包含 $G$ 的所有顶点，但是只包含边权值等于两个端点顶标之和的边，即 $E_l=\{(x,y):l(x)+l(y)=w(x,y)\}$ .

> Kuhn-Munkres 定理
>
> 如果 $l$ 是可行顶标， $M$ 是相等子图 $E_l$ 的完美匹配，那么 $M$ 是 $G$ 的最大权匹配

证明：任取 $G$ 的一个完美匹配 $M'$ 都有不等式

$$
w(M')=\sum_{e\in M'}w(e)\leqslant \sum_{e\in M'}l(e_x)+l(e_y)=\sum_{v\in V}l(v)
$$

说明任何一个完美匹配的边权值之和的上界就是所有顶标和，也等于完美匹配 $M$ 的边权和，因此 $M$ 是 $G$ 的最大权值匹配。KM 定理将求最大权匹配问题转化成了求完美匹配问题。KM 算法的核心就在于寻找可行顶标，使得相等子图有完美匹配。可行顶标的修改过程中，每一步都运用了**贪心**的思想，这样我们的最终结果一定是最优的。

### Algorithm

算法的大概框架为：

1. 给定初始的可行顶标 $l$ 和匹配 $M$ .
2. 当 $M$ 不是相等子图 $E_l$ 的完美匹配时，重复以下操作：
    - 在 $E_l$ 中搜索增广路径，如果存在，取反使得匹配数增加1。
    - 如果搜索增广路径失败，将可行顶标 $l$ 改进为 $l'$ 使得 $E_l\subset E_{l'}$ ，然后再重新搜索。

如果 $G$ 存在完美匹配，那么每次迭代过程中，要么匹配数增加1，要么相等子图扩大，最终算法一定会停止，停止时的 $M$ 就是 $E_l$ 的完美匹配，也是 $G$ 的最大权匹配。

---

初始时刻，我们构造一个简单的可行顶标： $Y$ 的顶标全部取0， $X$ 的顶标取每个点所连的边的最大权值

$$
\forall y\in Y,l(y)=0,\quad \forall x\in X,l(x)=\max_{y\in Y}\{w(x,y)\}
$$

这样显然满足可行顶标的要求。如果把这些最大权重对应的边找出来，其实就得到了相等子图。

初始匹配可设置为空集 $M=\varnothing$ .

改进可行顶标时，如果当前 $M$ 不是相等子图 $E_l$ 的完美匹配，是因为当前某个未匹配顶点（自由顶点） $u$ 出发，我们找不到它出发的一条增广路径，只能找到一个交替路径（以匹配的边和未匹配的边交替，但两端不都是自由顶点。至于为什么一定能找到交替路，稍后会解释）。我们定义 $X$ 中在交替路 $P$ 中的点集称为 $S=\{x\mid x\in P\cap X\}$ 、不在交替路中的点集为 $S'=X\backslash S$ ， $Y$ 中在交替路 $P$ 中的点集称为 $T=\{y\mid y\in P\cap Y\}$ 、不在交替路中的点集为 $T'=Y\backslash T$ .

如果我们把交替路中 $X$ 集顶点的顶标全都减小某个值 $\alpha_l$ ，同时 $Y$ 集的顶标全都增加同一个值 $\alpha_l$ ，那么我们会发现：

- 两端都在交替路中的边 $e_{i \to j}$ ， $l(i)+l(j)$ 的值不变。也就是说，它原来属于相等子图，现在仍属于相等子图。
- 两端都不在交替路中的边 $e_{i \to j}$ ， $l(i)+l(j)$ 的值不变。也就是说，它原来属于（或不属于）相等子图，现在仍属于（或不属于）相等子图。
- $X$ 端在 $S'$ 中， $Y$ 端在 $T$ 中的边 $e_{i \to j}$ ，它的 $l(i)+l(j)$ 的值增大。也就是说，它原来不属于相等子图，现在仍不可能属于相等子图。
- $X$ 端在 $S$ 中， $Y$ 端在 $T'$ 中的边 $e_{i \to j}$ ，它的 $l(i)+l(j)$ 的值减小。也就是说，它原来不属于相等子图，现在可能进入了相等子图，因而使相等子图得扩大。

也就是说，只有 $X$ 集一端在 $S$ 中， $Y$ 端在 $T'$ 中的边才有可能被选中。继续贪心，我们只选择满足条件的边权最大的边被选中，即满足 $l(x)+ l(y) = w(x,y)$ ，那么就应该取 $\alpha_l= \min\{l(x) + l(y) - w(x,y) \mid x \in S, y \in T'\}$ .

然后给所有顶点赋新的顶标：

$$
l'(v)=\begin{cases}
l(v)-\alpha_l, &v\in S \\
l(v)+\alpha_l,& v\in T \\
l(v),&\text{else}
\end{cases}
$$

$l'$ 也是一个可行顶标。于是有新的边加入相等子图，我们可以继续对未匹配顶点 $u$ 寻找增广路。这样的修改最多进行 $O(n)$ 次，而一共有 $n$ 个点，所以除去修改顶标的时间，复杂度已经达到 $O(n^2)$ 。因此，算法的复杂度主要取决于修改顶标的时间。

思路一：枚举所有 $n^2$ 条边，看是否满足条件，满足条件就更新 $\alpha_l$ 值。该方法最直观清晰，然而总的复杂度高达至 $O(|V|^4)$ 。

思路二：对于 $T'$ 的每个点 $v$ ，定义松弛变量 $slack(v)=\min\{l(x) + l(y) - w(x,y)\mid x \in S \}$，这个松弛变量在匹配的过程中就可以更新，修改顶标的过程中 $\alpha_l=\min\{ slack(v) \mid v \in T' \}$ ，总复杂度 $O(|V|^3)$ 。这样做但不是严格的，但实际上已经够用。

<br>

最终的伪代码如下：

1. 初始化可行顶标 $l$ 和相等子图 $E_l$ 的初始匹配 $M$ ：

    $$
    \forall y\in Y,\;l(y)=0,\quad \forall x\in X,\;l(x)=\max_{y\in Y}\{w(x,y)\},\quad M=\varnothing
    $$

2. 若 $M$ 是 $E_l$ 的完美匹配，终止算法。否则选取自由顶点 $u\in X$ ，令 $S=\{u\},\;T=\varnothing$ .
3. 若 $N_l(S)=T$ ，更新可行顶标：

    $$
    \alpha_l= \min_{x \in S, y \in Y\backslash T} \{l(x) + l(y) - w(x,y)\},\quad
    l'(v)=\begin{cases}
    l(v)-\alpha_l, &v\in S \\
    l(v)+\alpha_l,& v\in T \\
    l(v),&\text{else}
    \end{cases}
    $$

4. 若 $N_l(S)\neq T$ ，取 $v\in Y\backslash T$ ：
    - 若 $v$ 是自由顶点，那么找到了一条 $u\to v$ 的增广路径，取反使匹配数增加1，跳转至 Step 2。
    - 若 $v$ 不是自由顶点，设当前 $v$ 已经和 $z$ 匹配，则令 $S=S\cup\{z\},\;T=T\cup\{v\}$ ，跳转至 Step 3。

### Code

TODO

## Munkres Algorithm (Assignment Problem)

之前的 Kuhn-Munkres Algorithm 中，是以图论的方法，解决最大权重/最小代价问题。而一般考虑 Assignment Problem 时，常使用矩阵下的匈牙利算法，也就是 Munkres Algorithm（matrix reduction）。

> 以下部分内容跟参考自：
>
> [二分图匹配---Munkres算法 - 知乎 Zhihu](https://zhuanlan.zhihu.com/p/668517725)
>
> [匈牙利算法 (Hungarian Algorithm) - Jarvis's Blog](https://www.jarvis73.com/2022/05/23/Hungarian/)
>
> [多目标跟踪数据关联之匈牙利算法 - 知乎 Zhihu](https://zhuanlan.zhihu.com/p/571623539)

### Description

在任务指派问题（如 n 项工作由 n 个人承担，每个人完成不同工作所花时间不同，那如何分配使得花费的时间最少）以及一些多目标检测任务中的数据关联部分（如一个目标有多个特征点，有多个目标时检测到的特征点属于哪一个目标的问题）常常会看到 Munkres 算法，二分图匹配同样可以转换为指派问题，即将一侧的图看成工人，将另一侧的图看成任务，图与图之间的相似度可以转换成矩阵系数。

Munkres 算法的条件为：

- 系数矩阵（代价矩阵） $C\in \mathbb{R}^{n\times n}$ 为 $n$ 阶方阵，这样才可能存在完美匹配。
- 每一个系数为非负数 $c_{ij}>0$ .
- 求解目标为总代价的最小值。

定义变量：

$$
x_{ij}=\begin{cases}
1, &\text{指派第 i 个人完成第 j 项任务} \\
0, &\text{不指派第 i 个人完成第 j 项任务}
\end{cases}
$$

问题转化为：

$$
\min\sum_{i=1}^n\sum_{j=1}^n c_{ij}x_{ij},
\quad
\begin{cases}
\sum_{i=1}^n x_{ij}=1 \\
\sum_{j=1}^n x_{ij}=1 \\
x_{ij}=0 \text{ or } 1
\end{cases}
$$

也就是每一个人只能完成一项任务，每一项任务只能有一个任务完成，保证一一对应、完美匹配，体现在 $X=(x_{ij})$ 上就是每一行、每一列有且仅有 1 个 1，其余全为 0。

### Algorithm

首先我们介绍图论中的柯尼希定理（注意，与运动学中多质点系统的柯尼希定理不同）：

> König's theorem：在二部分图中，最大匹配数等于最小顶点覆盖数。
>
> 所谓一个顶点覆盖，是指顶点集的一个子集，图中每一条边都至少有一个顶点在这个子集中。
>
> ![20251028202214](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251028202214.png)
>
> 例如，在图中的二部图中，最大匹配（蓝边）和最小顶点覆盖（红点）数均为6。
>
> 如果用矩阵的语言描述，就是：在一个 0-1 矩阵中，“互不在同一行同一列的0元素的最多个数”等于“能够覆盖所有 0 元素的最小直线（行或列）数”。
>
> 匈牙利算法会对矩阵进行行列减法，使得部分元素变成 0。实际上，这些变成 0 的位置，就可以看作相等子图的一条边。而矩阵中一行或者一列所覆盖的零元素，就代表某个顶点所有的连接数。

Mubkres 算法的具体步骤。

1. 代价矩阵初始化：
    - Row reduction：代价矩阵的每一行减去该行的最小值。
    - Column reduction：代价矩阵的每一列减去该列的最小值。
    - > 这里用到的性质是，代价矩阵每一行或每一列减去一个相同的元素，最优解不变，因为最优解只关心如何分配指标和索引，不关心总代价的绝对大小。
2. 尝试分配寻找可行解：用最少的直线（横、竖）覆盖矩阵中所有0元素，如果直线个数等于矩阵的阶数 $n$ ，结束，否则执行 Step 3。
3. 找到未被覆盖元素中的最小值 $k$ ，所有未被覆盖的元素减去 $k$ ，被覆盖两次的元素加上 $k$ ，然后跳转至 Step 2。

下面看一个示例。我们有一个航迹测量代价矩阵，矩阵中元素表示航迹测量的匹配距离。

![20251028211155](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251028211155.png)

按照上述步骤，求解最小代价匹配的过程为：

![20251028211711](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251028211711.png)

---

上述过程比较直观易懂，但是问题在于，虽然人眼可以看出哪些直线可以覆盖所有的0，但是体现在代码上，如何找出覆盖所有0的最小的直线？

1957 年 James Munkres 引入了“标星 0（starred zeros）”和“标撇 0（primed zeros）”的概念以改进匈牙利算法原始流程中的划线法，在算法执行过程中会选择性地对代价矩阵中产生的 0 元素标记星号（*）或标记撇号（’）来辅助搜索增广路，标星 0 表示增广路中的匹配边，标撇 0 表示增广路中的未匹配边。

改进后的 Munkres 算法流程为：

1. 代价矩阵初始化：
    - Row reduction：代价矩阵的每一行减去该行的最小值。
    - Column reduction：代价矩阵的每一列减去该列的最小值。
2. Star zeros（目标：在每一行放置互不冲突的 star，作为匹配的雏形）
    - 逐行扫描矩阵，在每一行中，找到“不在 star 占用的列中的0”，找到的第一个对它标记 star，并标记这个 star 所在行和列都被覆盖，继续下一行。
    - 扫描完成后，如果所有 star 占用的列数等于矩阵的阶数 $n$ ，说明每一列都有一个 star，已经完成一一配对，终止算法。
    - 如果 star 没有覆盖全部的列，进入 Step 3。
3. Priming & Augmentation：循环进行以下操作：
    - 在未被之前行和列覆盖的元素中，找到一个0并标记 prime，并查看这一行后是否有 star。如果没找到 0，直接进入 Step 4。
    - 如果这一行没有 star，意味着找到了一条增广路径。构建增广路径：该 prime 为路径的首条边，若 prime 所在的列存在 star 则把 star 加入路径，若 star 所在的行存在 prime 则把 prime 加入路径，直到找不到 star 为止。把**路径中**所有 prime 变为 star，取消**路径中**所有 star 标记，然后清除**所有** prime，取消所有行覆盖。最后，检查所有 star 覆盖的列数是否等于矩阵阶数 $n$ ，如果等于，则找到完美匹配，终止算法，否则重新 Priming。
    - > 实际上，star 代表着暂时处于匹配中，prime 代表可能称为新的匹配，如果此时新加的 prime 的这一行没有 star，代表 prime 恰好比 star 多一个，也就构成了一条增广路径。这条增广路径从一个 prime 开始，找到同一列的 star，再从这个 star 找同一行的 prime，如此交替，知道遇到一个 prime 它所在的列没有 star。
    - 如果这一行已有 star，就盖住这一行（行覆盖），把那个已有 star 所在的列取消列覆盖，重新回到这一步的开始“寻找未覆盖元素中的 0 标记 prime”。
4. 生成新 0：找出未覆盖元素的最小值 $d$ ，当前所有未覆盖元素都减去 $d$ ，所有交叉覆盖（同时被行覆盖和列覆盖）的元素都加上 $d$ ，其余元素不变。这样就能在未覆盖区域生成新的 0，然后开始 Step 3 的 Priming。

接着上面的例子，使用改进算法的流程为（第一步进行了膨胀补 0，保证代价矩阵为方阵） ：

![20251028223755](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251028223755.png)

### Follow-up problems

（1）如果不是求最小代价，是求最大代价，如何处理？

找出代价矩阵中的最大值 max，然后令代价矩阵变为“max-代价矩阵各元素值”，得到新代价矩阵，再按照正常匈牙利法求解。

（2）如果系数矩阵不是方阵？

- 人数 > 工作：增加虚拟工作，虚拟工作对应的代价全设为0。
- 人数 < 工作：增加虚拟工人，虚拟工人对应的代价全设为0。

（3）如果某个人可以做多项工作？

如果一个工人可以做 $k$ 件事，那就把这个工人的代价复制 $k$ 份，相当于增加了虚拟人数。如果不是方阵，再添加虚拟工作。

（4）如果某个人不能做某项工作？

将问题转换为求最小值后，如果第 $i$ 个人不能做第 $j$ 项工作，可将代价 $c_{ij}$ 设置为一个比代价矩阵最大值更大的数。

### Code

下面分别给出 Munkres 算法的 Python 和 C++ 实现。其中 Python SciPy 库提供了 `scipy.optimize.linear_sum_assignment()` 函数可以直接调用，最为简单。

其中，C++ 的实现还可以参考 [Munkres’ Assignment Algorithm - The Algorithm Workshop - Bevilacqua](https://brc2.com/the-algorithm-workshop/)

=== "Python"

    ```py
    import numpy as np


    def hungarian(cost):
        cost = cost.copy().astype(float)
        n = cost.shape[0]

        # Step 1: 行列减法
        cost -= cost.min(axis=1, keepdims=True)
        cost -= cost.min(axis=0, keepdims=True)

        # 初始化标记矩阵：0=无标记, 1=star, 2=prime
        mark = np.zeros_like(cost, dtype=int)
        row_cover = np.zeros(n, dtype=bool)
        col_cover = np.zeros(n, dtype=bool)

        # Step 2: 初始打星
        for i in range(n):
            for j in range(n):
                if cost[i, j] == 0 and not row_cover[i] and not col_cover[j]:
                    mark[i, j] = 1  # star
                    row_cover[i] = col_cover[j] = True
                    break
        row_cover[:] = False
        col_cover[:] = np.any(mark == 1, axis=0)

        def find_zero():
            """未覆盖区域内搜索0，返回矩阵索引"""
            for i in range(n):
                if not row_cover[i]:
                    for j in range(n):
                        if cost[i, j] == 0 and not col_cover[j]:
                            return i, j
            return None, None

        def find_star_in_row(r):
            """某一行中搜素第一个 star zero"""
            c = np.where(mark[r] == 1)[0]
            return c[0] if c.size else None

        def find_star_in_col(c):
            """某一列中搜索第一个 star zero"""
            r = np.where(mark[:, c] == 1)[0]
            return r[0] if r.size else None

        def find_prime_in_row(r):
            """某一行中搜索第一个 prime zero"""
            c = np.where(mark[r] == 2)[0]
            return c[0] if c.size else None

        # Step 3 + Step 4 主循环
        while col_cover.sum() < n:
            # 寻找未覆盖的0
            while True:
                r, c = find_zero()
                if r is None:
                    # Step 4: 生成新0
                    d = np.min(cost[~row_cover][:, ~col_cover])
                    cost[~row_cover, :] -= d
                    cost[:, col_cover] += d
                else:
                    mark[r, c] = 2  # prime
                    star_c = find_star_in_row(r)
                    if star_c is None:
                        # 构建增广路径
                        path = [(r, c)]
                        while True:
                            star_r = find_star_in_col(path[-1][1])
                            if star_r is None:
                                break
                            path.append((star_r, path[-1][1]))
                            prime_c = find_prime_in_row(path[-1][0])
                            path.append((path[-1][0], prime_c))
                        # 翻转路径
                        for i, j in path:
                            mark[i, j] = 1 if mark[i, j] != 1 else 0
                        mark[mark == 2] = 0
                        row_cover[:] = False
                        col_cover[:] = np.any(mark == 1, axis=0)
                        break
                    else:
                        row_cover[r] = True
                        col_cover[star_c] = False

        # 输出结果
        result = np.zeros(n, dtype=int)
        for i in range(n):
            j = np.where(mark[i] == 1)[0][0]
            result[i] = j
        return result


    # 示例
    if __name__ == "__main__":
        np.random.seed(0)
        cost = np.random.randint(1, 21, size=(10, 10))
        print("代价矩阵：\n", cost)
        assign = hungarian(cost)
        print("最优匹配结果：")
        for i, j in enumerate(assign):
            print(f"行 {i + 1} → 列 {j + 1}, 代价 = {cost[i, j]}")
        print("总代价 =", cost[range(len(assign)), assign].sum())
    ```

=== "Python(using SciPy)"

    ```py
    import numpy as np
    from scipy.optimize import linear_sum_assignment

    np.random.seed(0)
    cost = np.random.randint(1, 21, size=(10, 10))

    print("代价矩阵：\n", cost)


    # 默认求最小代价，若求最大代价使用 -cost
    row_ind, col_ind = linear_sum_assignment(cost)

    print("\n最优匹配结果：")
    for r, c in zip(row_ind, col_ind):
        print(f"行 {r + 1} → 列 {c + 1}, 代价 = {cost[r, c]}")
    print("总代价 =", cost[row_ind, col_ind].sum())
    ```

=== "C++"

    ```cpp
    #include <iostream>
    #include <vector>
    #include <utility>
    #include <cstdlib>
    #include <iomanip>
    #include <cmath>
    using namespace std;

    vector<int> hungarian(const vector<vector<double>> &cost_matrix)
    {
        int n = cost_matrix.size();
        vector<vector<double>> cost = cost_matrix;
        vector<vector<int>> mark(n, vector<int>(n, 0)); // 0=none, 1=star, 2=prime
        vector<bool> row_cover(n, false), col_cover(n, false);

        // ---- Step 1: Row & Column reduction ----
        for (int i = 0; i < n; i++) {
            double minval = *min_element(cost[i].begin(), cost[i].end());
            for (int j = 0; j < n; j++) cost[i][j] -= minval;
        }
        for (int j = 0; j < n; j++) {
            double minval = 1e18;
            for (int i = 0; i < n; i++) minval = min(minval, cost[i][j]);
            for (int i = 0; i < n; i++) cost[i][j] -= minval;
        }

        // ---- Step 2: Star zeros ----
        for (int i = 0; i < n; i++)
            for (int j = 0; j < n; j++)
                if (fabs(cost[i][j]) < 1e-9 && !row_cover[i] && !col_cover[j]) {
                    mark[i][j] = 1; // star
                    row_cover[i] = col_cover[j] = true;
                    break;
                }

        fill(row_cover.begin(), row_cover.end(), false);
        for (int j = 0; j < n; j++)
            for (int i = 0; i < n; i++)
                if (mark[i][j] == 1)
                    col_cover[j] = true;

        auto find_zero = [&]() -> pair<int,int> {
            for (int i = 0; i < n; i++)
                if (!row_cover[i])
                    for (int j = 0; j < n; j++)
                        if (!col_cover[j] && fabs(cost[i][j]) < 1e-9)
                            return make_pair(i, j);
            return make_pair(-1, -1);
        };

        auto find_star_in_row = [&](int r) -> int {
            for (int j = 0; j < n; j++) if (mark[r][j] == 1) return j;
            return -1;
        };
        auto find_star_in_col = [&](int c) -> int {
            for (int i = 0; i < n; i++) if (mark[i][c] == 1) return i;
            return -1;
        };
        auto find_prime_in_row = [&](int r) -> int {
            for (int j = 0; j < n; j++) if (mark[r][j] == 2) return j;
            return -1;
        };

        // ---- Step 3 + 4 loop ----
        while (count(col_cover.begin(), col_cover.end(), true) < n)
        {
            while (true)
            {
                pair<int,int> p = find_zero();
                int r = p.first, c = p.second;
                if (r == -1) {
                    // Step 4: generate new zeros
                    double d = 1e18;
                    for (int i = 0; i < n; i++) if (!row_cover[i])
                        for (int j = 0; j < n; j++) if (!col_cover[j])
                            d = min(d, cost[i][j]);

                    for (int i = 0; i < n; i++) {
                        if (!row_cover[i])
                            for (int j = 0; j < n; j++)
                                cost[i][j] -= d;
                        for (int j = 0; j < n; j++)
                            if (col_cover[j])
                                cost[i][j] += d;
                    }
                }
                else {
                    mark[r][c] = 2; // prime
                    int star_col = find_star_in_row(r);
                    if (star_col == -1) {
                        // augment path
                        vector<pair<int,int>> path;
                        path.push_back(make_pair(r, c));
                        while (true) {
                            int star_row = find_star_in_col(path.back().second);
                            if (star_row == -1) break;
                            path.push_back(make_pair(star_row, path.back().second));
                            int prime_col = find_prime_in_row(path.back().first);
                            path.push_back(make_pair(path.back().first, prime_col));
                        }
                        for (auto &pp : path) {
                            int i = pp.first, j = pp.second;
                            mark[i][j] = (mark[i][j] == 1 ? 0 : 1);
                        }
                        for (int i = 0; i < n; i++)
                            for (int j = 0; j < n; j++)
                                if (mark[i][j] == 2) mark[i][j] = 0;
                        fill(row_cover.begin(), row_cover.end(), false);
                        fill(col_cover.begin(), col_cover.end(), false);
                        for (int j = 0; j < n; j++)
                            for (int i = 0; i < n; i++)
                                if (mark[i][j] == 1)
                                    col_cover[j] = true;
                        break;
                    } else {
                        row_cover[r] = true;
                        col_cover[star_col] = false;
                    }
                }
            }
        }

        // 输出匹配结果
        vector<int> assign(n, -1);
        for (int i = 0; i < n; i++)
            for (int j = 0; j < n; j++)
                if (mark[i][j] == 1)
                    assign[i] = j;
        return assign;
    }

    int main()
    {
        int n = 10;
        srand(0);
        vector<vector<double>> cost(n, vector<double>(n));
        for (int i = 0; i < n; i++)
            for (int j = 0; j < n; j++)
                cost[i][j] = rand() % 20 + 1;

        cout << "代价矩阵：" << endl;
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++)
                cout << setw(3) << cost[i][j] << " ";
            cout << endl;
        }

        vector<int> assign = hungarian(cost);

        double total = 0;
        cout << "\n最优匹配结果：" << endl;
        for (int i = 0; i < n; i++) {
            cout << "行 " << i+1 << " → 列 " << assign[i]+1
                << " , 代价 = " << cost[i][assign[i]] << endl;
            total += cost[i][assign[i]];
        }
        cout << "总代价 = " << total << endl;
        return 0;
    }
    ```

!!! note

    上面介绍的三种匈牙利算法：

    - Kuhn 算法
    - KM 算法（Kuhn-Munkres）
    - Munkres 算法（矩阵匈牙利）

    本质上是相同的，都是为了解决最大权重/最小代价的匹配问题。其中，Kuhn 算法（**无权**图）是 KM 算法（**有权**图）的一种特殊情形，只需将 KM 算法中权重设置为0、1两个值，就退化为 Kuhn 算法。而 KM 算法和 Munkres 算法等价，是同一个问题的两种实现，前者使用**图论**方法（顶标、相等子图、松弛），后者使用**矩阵**方法（行列相减、最小子图覆盖0）。

---

接下来，介绍完了匈牙利算法这一基本思想，让我们正式进入目标跟踪领域常用的算法框架。

## SORT

> [ICIP 2016] Simple Online and Realtime Tracking
>
> Paper: <https://arxiv.org/abs/1602.00763>
>
> Code: <https://github.com/abewley/sort>

SORT 是多目标跟踪中最经典、最简洁的算法之一，常用在目标检测器（如 YOLO）之后的跟踪层（tracking layer），在检测器输入的的基础上，实时地为每个目标分配持续的身份 ID，实现帧间关联。

SORT 算法的整体流程是“卡尔曼滤波预测 + 匈牙利算法匹配 + ID 管理”：

1. 用卡尔曼滤波器预测上一帧目标的新位置。
2. 以 IoU 为代价运用匈牙利算法，将新检测框与预测框匹配。
3. 匹配成功的检测框更新状态，匹配失败的重新分配 ID 或删除 ID。

### Estimantion Model

卡尔曼滤波中，设定的状态变量为 $\mathbf{x}=[u,v,s,r,\dot{u},\dot{v},\dot{s}]^T$ ，其中：

- $u,v$ 为目标边界框的横纵坐标。
- $s$ 为边界框的尺寸/面积。
- $r$ 为边界框的宽高比 width/height，保持不变。

一般在短时间内，目标匀速运动，那么使用匀速运动模型：

$$
\mathbf{x}_{k|k-1} = \mathbf{F} \mathbf{x}_{k-1|k-1},\quad \mathbf{F} = \begin{pmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}
$$

### Data Association

卡尔曼滤波的预测阶段结束后，需要对预测框和检测框进行匹配。计算每一对预测框和检测框的交并比 IoU（intersection-over-union）：

$$
\mathrm{IoU}(A,B)=\frac{\mathrm{area}(A\cap B)}{\mathrm{area}(A\cup B)}
$$

IoU 越大，两个框越接近重合，越有可能对应同一个目标。我们希望匹配的每一对的 IoU 尽可能大，即最大化总 IoU，而匈牙利算法求解的是最小代价，因此可以设置代价为 $c_{ij}=1-\mathrm{IoU}(A_i,B_j)$ .

同时，为避免匹配中某一对 IoU 过小，还需要进行下界阈值 $\mathrm{IoU}_{\min}$ 进行过滤，宁愿不分配，也要避免分配错误的一对边界框。

轨迹生命周期管理（ID 管理）中，每个目标有 3 种可能状态：

- Active 跟踪中：匹配成功，正常更新。
- Lost 暂时丢失：本帧未匹配到检测框，但仍进行预测。
- Deleted 已删除：连续多帧未匹配到，认为目标丢失。

可以设置参数：

- `max_age` ：允许连续多少帧匹配失败就删除，也就是原文的 $T_{lost}$ 参数。
- `min_hits` ：最少连续命中多少次认为是真实目标，避免误检测。

SORT 的局限性在于：存在遮挡时会导致跟踪中断；IoU 对尺度变化较为敏感。

## DeepSORT

前述的 SORT 只用几何信息（预测框与检测框的 IoU/位置）做关联，而没有用到目标的特征，在遮挡和交会时容易发生 ID switch。因此 DeepSORT 增加了外观特征（ReID embedding），使得相似目标在遮挡后仍保持 ID，并使用匹配级联（matching cascade）和门控马氏距离使得数据关联更加稳定。

> [ICIP 2017] Simple Online and Realtime Tracking with a Deep Association Metric
>
> Paper: <https://arxiv.org/abs/1703.07402>
>
> Code: <https://github.com/nwojke/deep_sort>

### Track Handling and State Estimation

与 SORT 类似，构建常速度、线性观测的标准卡尔曼滤波模型。检测框的状态变量为 $\mathbf{x}=[u,v,\gamma,h,\dot{x},\dot{y},\dot{\gamma},\dot{h}]^T$ ，观测变量为 $\mathbf{z}=[u,v,\gamma,h]^T$ 。其中，此处使用宽高比 $\gamma$ 和高度 $h$ ，而非 SORT 使用的面积 $s$ .

对于每一个目标的跟踪轨迹 $k$ ，我们需要计数它从成功关联以来的帧数，也就是它连续关联失败的帧数，如果超过预设阈值 $A_{\max}$ ，认为它已经离开场景，终止该目标的跟踪。

对于无法与现有目标跟踪轨迹关联的检测，尝试分配新的 ID，如果连续 3 帧都能关联成功，就保留此目标。

### Assignment Problem

为了构建分配问题的代价、运用匈牙利算法，我们结合目标的**运行**信息和**外观**信息进行分析。

对于运动信息，使用卡尔曼预测状态和新到来的测量之间的平方马氏距离（Mahalanobis distance）：

$$
d^{(1)}(i,j)=(\mathbf{d}_j-\mathbf{y}_i)^T\mathbf{S}_i^{-1}(\mathbf{d}_j-\mathbf{y}_i)^T
$$

原文中是这么说的：

> ... where we denote the projection of the $i$-th track distribution into measurement space by $(\boldsymbol{y}_i,\boldsymbol{S}_i)$ and the $j$-th bounding box detection by $\boldsymbol{d}_j$ . The Mahalanobis distance takes state estimation uncertainty into account by measuring how many standard deviations the detection is away from the mean track location.

这里具体解释一下 $\mathbf{y}_i,\;\mathbf{S}_i$ 的含义。由于卡尔曼滤波中的状态变量是在状态空间中，我们需要通过观测矩阵 $\mathbf{H}$ 将预测的状态分布从状态空间映射到测量空间 $(\mathbf{x}_i,\mathbf{P}_i)\to(\mathbf{y}_i,\mathbf{S}_i)$ ，也就是：

$$
\mathbf{y}_i=\mathbf{H}\mathbf{x}_i,\quad \mathbf{S}_i=\mathbf{H}\mathbf{P}_i\mathbf{H}^T+\mathbf{R}
$$

因此， $\mathbf{y}_i$ 代表第 $i$ 个轨迹预测观测均值（即卡尔曼滤波预测的测量输出）， $\mathbf{S}_i$ 代表第 $i$ 个轨迹预测在测量空间中的协方差矩阵（即卡尔曼滤波的不确定性）。

这个马氏距离衡量了检测框距离预测分布的中心有多少个标准差。马氏距离在计算预测与检测之间差距时，会考虑状态估计的不确定性，比欧氏距离更加合理，能够动态适应“预测置信度”：

- 若某个预测位置很确定（协方差小），即预测框范围很“窄”，那么偏离一点点就意味着很大的马氏距离。
- 若某个预测位置很不确定（协方差大），允许更大误差。

为了排除不太可能的匹配，在 95% 置信度区间内，对马氏距离进行阈值处理：

$$
b^{(1)}(i,j)=\mathbb{I}[d^{(1)}(i,j)\leqslant t^{(1)}],\quad t^{(1)}=\chi_4^2(0.95)=9.4877
$$

> While the Mahalanobis distance is a suitable association metric when motion uncertainty is low, in our image-space problem formulation the predicted state distribution obtained from the Kalman filtering framework provides only a rough estimate of the object location. In particular, unaccounted camera motion can introduce rapid displacements in the image plane, making the Mahalanobis distance a rather uninformed metric for tracking through occlusions. Therefore, we integrate a second metric into the assignment problem.

这段话的意思是，目标运动的不确定性较低时，使用马氏距离较为合适。但是在图像坐标系中，卡尔曼滤波预测的状态往往知识一个粗略估计，当存在相机抖动、不规则运动时，目标会在图像上出现大幅度漂移，此时马氏距离的区分程度变差，难以在遮挡或者快速移动场景中有效工作。

因此我们引入外观度量（appearance metric）：

- 对每一个检测到的边界框 $\mathbf{d}_j$ ，经过一个预训练 CNN（ReID 网络）提取特征向量 $\mathbf{r}_j$ ，保证 L2 归一化 $\|\mathbf{r}_j\|=1$ .
- 对每条轨迹（track） $k$ 维护一个特征库 $\mathcal{R}_k=\{\mathbf{r}_k^{(i)}\}_{k=1}^{L_k}$ 保存最近的 $L_k=100$ 帧该目标的特征。保存多帧是为了即使目标被短暂遮挡，也能用旧特征重新识别回来。
- 对于第 $i$ 条轨迹、第 $j$ 条观测，计算特征 $\mathbf{r}_j$ 与轨迹历史特征集 $\mathcal{R}_i$ 中所有特征的余弦距离最小值，作为该匹配对的外观距离 $d^{(2)}(i,j)=\min\{1-\mathbf{r}_j^T\mathbf{r}_k^{(i)} \mid \mathbf{r}_k^{(i)}\in\mathcal{R}_i \}$ . （余弦距离越小，代表两个特征越相似。这里用1减去，是因为要求最小代价）
- 再使用阈值判断 $b^{(2)}(i,j)=\mathbb{I}[d^{(2)}(i,j)\leqslant t^{(2)}]$ .

<br>

马氏距离反映了运动位置信息，适合短期预测；余弦距离提供外观特征，适合长期保持、应对遮挡问题。最后使用它们的加权求和来构建一个配对的最终代价：

$$
c_{ij}=\lambda d^{(1)}(i,j)+(1-\lambda)d^{(2)}(i,j)
$$

同时，这两个距离必须**同时**在门控范围内 $b_{ij}=b_{ij}^{(1)}b_{ij}^{(2)}$ ，这个代价 $c_{ij}$ 才有效。

在实际测试中，如果存在明显的相机运动，设置 $\lambda=0$ 较为合适，虽然最终代价只用到了外观距离，但是马氏距离仍然用于排除不太可能的分配，仍然在起作用。

### Matching Cascade

> Instead of solving for measurement-to-track associations in a global assignment problem, we introduce a cascade that solves a series of subproblems. To motivate this approach, consider the following situation: When an object is occluded for a longer period of time, subsequent Kalman filter predictions increase the uncertainty associated with the object location. Consequently, probability mass spreads out in state space and the observation likelihood becomes less peaked. Intuitively, the association metric should account for this spread of probability mass by increasing the measurement-to-track distance. Counterintuitively, when two tracks compete for the same detection, the Mahalanobis distance favors larger uncertainty, because it effectively reduces the distance in standard deviations of any detection towards the projected track mean. This is an undesired behavior as it can lead to increased track fragmentations and unstable tracks. Therefore, we introduce a matching cascade that gives priority to more frequently seen objects to encode our notion of probability spread in the association likelihood.

文中指出这样一个问题：当一个目标被遮挡时间越来越长时，卡尔曼滤波预测的位置越来越不准确，预测误差会不断积累，协方差（不确定性）变大。也就是 $\mathbf{S}_i$ 变大、 $\mathbf{S}_i^{-1}$ 变小、马氏距离“虚假地”变小，算法产生“错觉”，误以为当前的检测框和旧的轨迹很匹配。

DeepSORT 提出的思路是，与其像 SORT 那样一次性在所有轨迹上做全局匹配，不如优先考虑最近更新过的轨迹（预测较准的），然后再考虑比较老的轨迹（预测不准的）。

伪代码为：

```yaml
Listing 1: Matching Cascade

Input:
  Track indices T = {1,...,N}
  Detection indices D = {1,...,M}
  Maximum age Amax

1: Compute cost matrix C = [c_ij] using Eq.5        # 综合代价矩阵
2: Compute gate matrix B = [b_ij] using Eq.6        # 可行匹配（门控）
3: Initialize set of matches M ← ∅
4: Initialize unmatched detections U ← D
5: for n ∈ {1,...,Amax} do
6:     Select tracks by age Tn ← {i ∈ T | a_i = n}
7:     [x_i, y_i] ← min_cost_matching(C, Tn, U)     # 对这些轨迹局部匈牙利匹配
8:     M ← M ∪ {(i,j)} | b_ij ≠ 0
9:     U ← U \ {j | ∃ i, (i,j) ∈ M}                 # 移除已匹配检测
10: end for
11: return M, U
```

具体的流程为：

1. 准备代价矩阵 $\mathbf{C}=(c_{ij})$ 和门控矩阵 $\mathbf{B}=(b_{ij})$ ， $b_{ij}=1$ 才表示该配对满足阈值条件。
2. $\mathcal{M}$ 保存已经配对的“轨迹预测框-检测框”， $\mathcal{U}$ 保存还未匹配的检测框索引。
3. 按轨迹的年龄 $n$ （距离上次匹配成功的帧数）从小到大逐级匹配
    - 取出轨迹中的“同龄者” $\mathcal{T}_n=\{i\in\mathcal{T}\mid a_i=n\}$ .
    - 局部匈牙利算法：最小化代价矩阵的子集 $\mathbf{C}[\mathcal{T}_n,\mathcal{U}]$ .
    - 把得到的匹配对加入集合 $\mathcal{M}$ ，把本次匹配到的检测框从 $\mathcal{U}$ 中移除。
4. 级联匹配后，再做一次 IoU 匹配，用于还未匹配的、“年龄=1”的轨迹，

级联匹配策略按轨迹“新鲜度”分层，从最新匹配的轨迹开始逐步匹配，避免被遮挡时间长、预测不准的轨迹抢占检测框。这一机制显著减少了 ID Switch，是 DeepSORT 的关键稳定性来源。

### Deep Appearance Descriptor

本方法的在线跟踪使用最近邻查询（nearest neighbor queries），无需额外的度量学习。使用 MARS 数据训练一个 CNN，得到具有较好区分度的特征嵌入。

网络的最后一层做 BatchNorm + L2 Norm，输出一个 128 维向量，将向量投影到单位超球面，消除尺度影响，且此时余弦距离=点积。

## ByteTrack

> [ECCV 2022] ByteTrack: Multi-Object Tracking by Associating Every Detection Box
>
> Paper: <https://arxiv.org/abs/2110.06864>
>
> Code: <https://github.com/FoundationVision/ByteTrack>
>
> Translation: <https://zhuanlan.zhihu.com/p/645645269>

大多数的 MOT 算法，只关心置信度（分数）大于阈值的检测框来获取 ID，置信度较低的目标（例如被遮挡的）被丢弃，可能造成真值目标丢失或轨迹碎片化。本文提出，通过关联几乎每个检测框进行跟踪，对于低置信度目标，利用它和轨迹的相似度来恢复真值目标、过滤对背景的检测。

> 消除所有低置信度检测框的做法是正确的吗？本文答案是否定的。正如黑格尔所说，“存在即合理”。低置信度检测框有时表明目标是存在的，例如被遮挡的目标。

如果一个目标在跟踪过程中发生短暂遮挡，它的边界框置信度会发生短暂下降。但是通过降低置信度阈值并不能解决这个问题，因为仅仅降低置信度阈值又会导致非目标被错误地“框出来”，也就是 false positives。

### BYTE

> 主流方法都专注于设计更好的数据关联方式。然而本文认为检测框的使用方式决定了数据关联的上限，并且专注于在匹配过程中充分利用从高分到低分的检测框。

几乎保留所有检测的边界框，分为高分和低分两类。首先将高分检测框与现有轨迹做关联匹配。发生遮挡、运动模糊或者尺寸改变时，某些轨迹可能找不到对应的匹配。

将低分检测框与剩余未匹配的轨迹做匹配。如果低分检测框中有真实目标，则匹配到对应的轨迹，如果没有真实目标，则因为未匹配到轨迹而丢弃。这样就能恢复低分检测框中的目标，同时过滤掉背景。

算法框架为：

1. 检测框分组：按置信度阈值 $\tau$ 将检测框分为高分组 $\mathcal{D}_{high}$ 和低分组 $\mathcal{D}_{low}$ .
2. 轨迹预测：对每一条轨迹使用卡尔曼滤波预测，得到当前帧的预测框位置。
3. Fisrt Association：对轨迹集合 $\mathcal{T}$ 和高分组检测框 $\mathcal{D}_{high}$ 做匈牙利算法最优匹配，相似度使用 IoU 距离或者 IoU + ReID。未匹配的轨迹记为 $\mathcal{T}_{remain}$ ，未匹配的检测框记为 $\mathcal{D}_{remain}$ .
4. Second Association：对 $\mathcal{T}_{remain}$ 和 $\mathcal{D}_{low}$ 做最优匹配，仅使用 IoU 距离计算代价（因为低置信度框通常外观特征不可靠）。仍未匹配的轨迹记为 $\mathcal{T}_{re-remain}$ .
5. 删除长期未匹配的轨迹 $\mathcal{T}\gets \mathcal{T}\backslash\mathcal{T}_{re-remain}$ ，然后建立新的轨迹 $\mathcal{T}\gets \mathcal{T}\cup \mathcal{D}_{remain}$ .
6. 为了保留可能临时丢失的目标，将 $\mathcal{T}_{re-remain}$ 中的轨迹放入 $\mathcal{T}_{lost}$ ，而 $\mathcal{T}_{lost}$ 中的每个轨迹存留 30 帧以上才删除它。
7. 每一帧的输出是 $\mathcal{T}$ 中轨迹的边界框和 ID。

![20251030215650](https://cdn.jsdelivr.net/gh/DerrickMarcus/picgo-image/images/20251030215650.png)

基于 BYTE 设计出跟踪器：ByteTrack = YOLOX(detector) + BYTE(association)

### Bounding Box Annotations

MOT17 数据集中，每个人的边界框覆盖了整个身体，即使他被遮挡或者有部分到了图像之外（边界框也会延伸到图像之外）。但是 YOLOX 默认会把边界框裁剪到图像之内，为避免检测出错，本文修改了 YOLOX 的数据预处理和标签分配策略：

1. 在预处理和数据增强阶段，不在裁剪超出图像的检测框，只删除完全在图像之外的检测框。
2. MOT17 数据集标注中，人的中心点可能在图像之外。YOLOX 的标签分配策略 SimOTA 要求正样本围绕目标中心分布，因此在分配正样本时可能因为中心点超出图像而失效。这种情况下，只把中心点裁到图像内，不裁剪边界框。

MOT20、HiEve 和 BDD100K 数据集的标注，已经将标注的边界框裁剪到图像内，因此无需改动 YOLOX。

### Tracklet Interpolation

MOT17 数据集中，有一些被完全遮挡的行人，YOLOX 无法输出他们的检测框。如果某个目标在被检测到的两帧之间被遮挡，可以使用线性插值“找回”中间的几帧。

假设某轨迹 $T$ 在第 $t_1$ 帧的检测框为 $B_{t1}$ ，第 $t_2$ 帧的检测框为 $B_{t2}$ ，插入中间帧：

$$
B_t=B_{t1}+(B_{t2}-B_{t1})\frac{t-t_1}{t_2-t_1}, \quad t_1<t<t_2
$$

其中检测框 $B_t=[x_{tl},y_{tl},x_{br},y_{br}]\in\mathbb{R}^4$ 代表左上和右下坐标，同时还应该限制遮挡时间不超过最大间隔才进行插值补帧 $t_2-t_1<\sigma$ .

## BoT-SORT

> [CVPR 2023] BoT-SORT: Robust Associations Multi-Pedestrian Tracking
>
> Paper: <https://arxiv.org/abs/2206.14651>
>
> Code: <https://github.com/NirAharon/BoT-SORT>

BoT-SORT 把运动信息（Kalman 预测 + IoU）与外观信息（ReID 特征）融合，同时显式做相机运动补偿（CMC），并把 Kalman Filter 的状态向量从传统的“中心+面积+纵横比”改为“中心 + 宽高”，集成到 ByteTrack 中，提出了 BoT-SORT 和 BoT-SORT-ReID 两种跟踪器。两者的主干相同：

1. 基于 ByteTrack 的两阶段匹配（高置信 + 低置信检测）。
2. Kalman Filter 预测更新。
3. 相机运动补偿。
4. IoU 匹配 / 门控 / 匈牙利算法
5. 轨迹生命周期管理

区别是，在匹配时是否引入 ReID 外观特征。

### Kalman Filter

与 SORT、DeepSORT 都不同，BoT-SORT 选定的状态变量为 $\boldsymbol{x}=[x,y,w,h,\dot{x},\dot{y},\dot{w},\dot{h}]^T$ ，即二维坐标、宽度高度及其变化量。观测变量为 $\boldsymbol{z}=[x,y,w,h]$ .

状态转移矩阵和观测矩阵分别为：

$$
\boldsymbol{F}=\begin{pmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
\end{pmatrix},\quad
\boldsymbol{H}=\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
\end{pmatrix}
$$

采用与时间相关的过程噪声和测量噪声：

$$
\begin{align*}
\boldsymbol{Q}_k = \text{diag}(&(\sigma_p \hat{w}_{k-1|k-1})^2, (\sigma_p \hat{h}_{k-1|k-1})^2,\\
&(\sigma_p \hat{w}_{k-1|k-1})^2, (\sigma_p \hat{h}_{k-1|k-1})^2,\\
&(\sigma_v \hat{w}_{k-1|k-1})^2, (\sigma_v \hat{h}_{k-1|k-1})^2,\\
&(\sigma_v \hat{w}_{k-1|k-1})^2, (\sigma_v \hat{h}_{k-1|k-1})^2)
\\
\boldsymbol{R}_k = \text{diag}(&(\sigma_m \hat{w}_{k|k-1})^2, (\sigma_m \hat{h}_{k|k-1})^2,\\
&(\sigma_m \hat{w}_{k|k-1})^2, (\sigma_m \hat{h}_{k|k-1})^2)
\end{align*}
$$

过程噪声 $\boldsymbol{Q}_k$ 和测量噪声 $\boldsymbol{R}_k$ 是随边界框尺寸动态变化的对角阵， $\sigma_p,\sigma_v,\sigma_m$ 是需要设定的参数。

### Camera Motion Compensation

相机本身会运动的场景中，图像中的边界框可能发生显著变化。相机静止时，也可能受到风引起的振动或漂移。在未知相机运动数据（导航、IMU）或者相机内参矩阵时，可以使用相邻帧之间图像配准，近似看作相机运动在图像上的投影。

使用 OpenCV 中的全局运动估计（GMC，global motion compensation），这种稀疏配准技术允许忽略场景中动态物体，从而更好地估计背景的运动：

1. 提取图像关键点（keypoints）。
2. 使用稀疏光流（sparse optical flow）进行特征跟踪，并对平移分量做阈值处理。
3. 使用 RANSAC（Random Sample Consensus 随机抽样一致）估计相邻帧之间的仿射变换 $\boldsymbol{A}_{k-1}^k\in\mathbb{R}^{2\times 3}$ .

$$
\boldsymbol{A}_{k-1}^k=[\boldsymbol{M}_{2\times 2}\mid \boldsymbol{T}_{2\times 1}]=
\begin{pmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23}
\end{pmatrix}
$$

使用该仿射变换可以预测第 $k-1$ 帧的边界框在第 $k$ 帧中的位置。其中平移部分 $\boldsymbol{T}$ 只影响边界框的中心坐标，不影响宽度、高度和其变化率。而旋转部分 $\boldsymbol{M}$ 对状态变量和噪声都有影响，但由于是线性变换，该仿射矩阵也可以同时同等地作用于整个状态变量，因此我们构造矩阵：

$$
\tilde{\boldsymbol{M}}_{k-1}^k=\begin{pmatrix}
\boldsymbol{M} & 0 & 0 & 0 \\
0 & \boldsymbol{M} & 0 & 0 \\
0 & 0 & \boldsymbol{M} & 0 \\
0 & 0 & 0 & \boldsymbol{M} \\
\end{pmatrix}\in\mathbb{R}^{8\times 8},\quad
\tilde{\boldsymbol{T}}_{k-1}^k=\begin{pmatrix}
a_{12} \\ a_{13} \\ 0 \\ \vdots \\ 0
\end{pmatrix}\in\mathbb{R}^8
$$

假设我们有了原始 KF 预测的状态变量和协方差 $\hat{\boldsymbol{x}}_{k|k-1},\;\boldsymbol{P}_{k|k-1}$ ，补偿后的预测应该修正为：

$$
\begin{align*}
\hat{\boldsymbol{x}}'_{k|k-1}&=\tilde{\boldsymbol{M}}_{k-1}^k \hat{\boldsymbol{x}}_{k|k-1}+\tilde{\boldsymbol{T}}_{k-1}^k \\
\boldsymbol{P}'_{k|k-1}&=\tilde{\boldsymbol{M}}_{k-1}^k \boldsymbol{P}_{k|k-1} \left(\tilde{\boldsymbol{M}}_{k-1}^{k}\right)^T
\end{align*}
$$

此结果作为最终的预测值，再与当前检测/观测 $\boldsymbol{z}$ 做更新：

$$
\begin{align*}
\boldsymbol{K}_k &= \boldsymbol{P}'_{k|k-1} \boldsymbol{H}_k^T \left(\boldsymbol{H}_k \boldsymbol{P}'_{k|k-1} \boldsymbol{H}_k^T + \boldsymbol{R}_k\right)^{-1}
\\
\hat{\boldsymbol{x}}_{k|k} &= \hat{\boldsymbol{x}}'_{k|k-1} + \boldsymbol{K}_k \left(\boldsymbol{z}_k - \boldsymbol{H}_k \hat{\boldsymbol{x}}'_{k|k-1}\right)
\\
\boldsymbol{P}_{k|k} &= \left(\boldsymbol{I} - \boldsymbol{K}_k \boldsymbol{H}_k\right) \boldsymbol{P}'_{k|k-1}
\end{align*}
$$

相机高速运动场景下，上述运动补偿至关重要。相机缓慢运动时，可忽略对 $\boldsymbol{P}_{k|k-1}$ 的补偿。

### IoU-ReID Fusion

类似于 DeepSORT，首先采用 FastReID 库的 BoT-SBS 模型（以 ResNeSt-50 主干），提取 128-D 或 256-D 的 embedding 特征嵌入。

每一条轨迹（tracklet）维护一个**外观状态** $e_i^k$ ，表示第 $i$ 条轨迹在第 $k$ 帧的平均外观特征，并使用指数滑动平均（EMA，exponential moving average）进行更新：

$$
e_i^k=\alpha e_i^{k-1} +(1-\alpha)f_i^k
$$

其中 $f_i^k$ 为当前帧检测到的边界框对应的 embedding， $\alpha=0.9$ 为动量，表示新特征只占 10% 的权重。这样可以平滑 ReID 特征。

对每一条轨迹 $i$ 的平均外观特征 $e_i^k$ 和检测 $j$ 的特征 $f_j^k$ 计算余弦相似度 $d_{i,j}^{\cos}=1-e_i^k\cdot f_j^k$ .

> 不同于 DeepSORT 把 IoU 距离和特征的余弦距离的加权平均作为最终代价，BoT-SORT 采用了更保守的方法：取最小值。

首先进行两次阈值处理，得到新的余弦距离：

$$
\hat{d}_{i,j}^{\cos}=\begin{cases}
0.5 \cdot d_{i,j}^{\cos}, & \text{if } (d_{i,j}^{\cos}<\theta_{emb})\wedge (d_{i,j}^{iou}<\theta_{iou})\\
1, & \text{else}
\end{cases}
$$

若 IoU 和余弦距离都在阈值内，说明重合程度较高，赋予一个更小的距离 $0.5 \cdot d_{i,j}^{\cos}$ ，否则直接设为 1，表示不可能匹配。原文中设置参数 $\theta_{emb}=0.25,\;\theta_{iou}=0.5$ .

最终的代价取最小值 $c_{ij}=\min\{d_{i,j}^{iou},\hat{d}_{i,j}^{\cos}\}$ ，这样一来：

- 如果外观相似且位置相近，则使用更小的那个距离。
- 如果外观和位置有任何一个不可信，则把外观代价设为 1，相当于使用 IoU 位置距离，退化为纯 IoU 匹配。

## JDE

## FairMOT

[^1]: [1]吴楚峥.基于深度学习的单目摄像头人员跟踪定位方法研究[D].西安科技大学,2022.DOI:10.27397/d.cnki.gxaku.2022.001665.
